{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571a0ea8-5c9b-443d-aabf-cd3a045d19ac",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import spacy, nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"stopwords\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a1c42-5665-40da-8cf9-86f215838383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/fake_job_postings.csv').drop(['job_id', 'salary_range', 'location'], axis=1)\n",
    "\n",
    "for col, pct_null in pd.Series(df.isna().sum() / len(df)).items():\n",
    "    if pct_null < .05:\n",
    "        df.dropna(subset=[col], inplace=True)\n",
    "    else:\n",
    "        df[col].fillna('not provided', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389dd647-9dc9-4f2b-a1a8-f4ad1a9c1107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9515fb-c955-4c8a-920a-08ffabb8c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_TEXT_TEMPLATE = \"\"\"\n",
    "# {title}\n",
    "\n",
    "Employment Type: {employment_type}\n",
    "Department: {department}\n",
    "Industry: {industry}\n",
    "Function: {function}\n",
    "Required Experience: {required_experience}\n",
    "Required Education: {required_education}\n",
    "\n",
    "# Company Profile\n",
    "{company_profile}\n",
    "\n",
    "# Description\n",
    "{description}\n",
    "\n",
    "# Requirements\n",
    "{requirements}\n",
    "\n",
    "# Benefits\n",
    "{benefits}\n",
    "\"\"\"\n",
    "\n",
    "def get_full_text_feature(row):\n",
    "    return FULL_TEXT_TEMPLATE.format(\n",
    "        title=row[\"title\"], employment_type=row[\"employment_type\"], department=row[\"department\"],\n",
    "        industry=row[\"industry\"], function=row[\"function\"], required_experience=row[\"required_experience\"],\n",
    "        required_education=row[\"required_education\"], company_profile=row[\"company_profile\"],\n",
    "        description=row[\"description\"], requirements=row[\"requirements\"], benefits=row[\"benefits\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1b6a1-fe07-47d9-a33f-5b56b53e9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_text_feature'] = df.apply(lambda row: get_full_text_feature(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ba58a-5a46-4549-b3b9-7c32df0cdf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = df['full_text_feature'].values\n",
    "print(text_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a61e33-3611-4d63-95fb-b5e2702b4844",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_entities = []\n",
    "\n",
    "for feat in tqdm(text_features[:10]):\n",
    "    doc = nlp(feat)\n",
    "    entities = [{\"text\": ent.text, \"label\": ent.label_} for ent in doc.ents]\n",
    "    text_entities.append({\n",
    "        \"text\": feat,\n",
    "        \"entities\": entities\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d068dc96-088c-4fff-8f04-32416b7101e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,3), stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea4b9c-3817-4554-a7a8-167e11e174ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1ffef-e0da-4ed6-9d50-14c69149ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=5)\n",
    "doc_topics = nmf.fit_transform(X_tfidf)\n",
    "topic_words = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a61e30-cb5e-4e88-aa10-3e2ef2390b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61e12c-25fd-4956-b152-6a577999fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in enumerate(topic_words):\n",
    "    top_words = [feature_names[i] for i in topic.argsort()[:-6:-1]]\n",
    "    print(f\"Topic #{idx + 1}: {' | '.join(top_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a0994-108d-489a-a6f3-bd8943d8b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_top_topics = np.argmax(doc_topics, axis=1)\n",
    "for i, doc in enumerate(text_features[:3]):\n",
    "    print(f\"\\nDocument {i} (Topic {doc_topics[i]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbba6e-6b39-4bdc-a644-3c2079482b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# X_bert = embedding_model.encode(text_features, normalize_embeddings=True)\n",
    "# joblib.dump(X_bert, './datasets/X_bert.joblib')\n",
    "\n",
    "X_bert = joblib.load('./datasets/X_bert.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac07c59b-0435-44d5-afea-1d355876840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_model = BERTopic()\n",
    "topics, probs = bert_topic_model.fit_transform(text_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a33263c-957b-44a1-9173-553c5c87a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows topic and probabilities for 0th doc\n",
    "topics[0], probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b10662-9b27-4f12-aa0d-8d396a1af07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_model.get_topic(topics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0f91b-3f40-4081-a97c-1e9e6d598aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefd37f-8726-4511-8577-35662980cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = []\n",
    "vectorized_sentences = []\n",
    "for f in text_features:\n",
    "    tokens = word_tokenize(f.lower())\n",
    "    clean_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    tokenized_sentences.append(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12b4a2c-592f-4899-8895-561ad9c8cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokenized_sentences)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a1482-6d3a-4f72-a2ff-368117957971",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c0e64-f736-48ee-874e-287b167be95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=2, random_state=42)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c815ff-a27f-49c7-872e-a6e3a34157f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd72374-1be4-4ef7-9448-1294f439ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_features)\n",
    "X_tok = tokenizer.texts_to_sequences(text_features)\n",
    "X_tok = pad_sequences(X_tok, maxlen=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2987b9-e5b3-4322-be82-3efa42552e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home_lab",
   "language": "python",
   "name": "home_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
